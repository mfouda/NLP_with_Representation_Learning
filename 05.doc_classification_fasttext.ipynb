{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Document Classification with FastText\n",
    "\n",
    "After building a classifier with Bag-of-Words, we will try N-grams embedding in this section. The model we use is [FastText](https://github.com/facebookresearch/fastText) from Facebook Research. Again, we will perform a multi-class classification and see how we can make progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same dataset from previous notebook (04.bag_of_words), download data from:\n",
    "\n",
    "http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# To be used for pre-processing of data\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading\n",
    "First, let's load the dataset from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroup_train = fetch_20newsgroups(subset='train')\n",
    "newsgroup_test = fetch_20newsgroups(subset='test') # we will use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 10000\n",
      "Val dataset size is 1314\n",
      "Test dataset size is 7532\n"
     ]
    }
   ],
   "source": [
    "train_split = 10000\n",
    "train_data = newsgroup_train.data[:train_split]\n",
    "train_targets = newsgroup_train.target[:train_split]\n",
    "\n",
    "val_data = newsgroup_train.data[train_split:]\n",
    "val_targets = newsgroup_train.target[train_split:]\n",
    "\n",
    "test_data = newsgroup_test.data\n",
    "test_targets = newsgroup_test.target\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocessing\n",
    "Fasttext library takes a file as input and learn a classification model.\n",
    "The sentences in input file should be in this format: \"_ __label__ _[class] [Text]\" \n",
    "We will prepare the train file and test file in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_newsgroup_file(data, targets, outfile_name):\n",
    "    with open(outfile_name, 'w') as fout:\n",
    "        for i, sent in enumerate(data):\n",
    "            line = \"__label__\" + str(targets[i]) + \" \" + sent.replace('\\n', ' ') + \"\\n\"\n",
    "            fout.write(line)\n",
    "            \n",
    "\n",
    "create_newsgroup_file(train_data, train_targets, 'data/newsgroups.train') \n",
    "create_newsgroup_file(val_data, val_targets, 'data/newsgroups.val') \n",
    "create_newsgroup_file(test_data, test_targets, 'data/newsgroups.test') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the file we created look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__7 From: lerxst@wam.umd.edu (where's my thing) Subject: WHAT car is this!? Nntp-Posting-Host: rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: 15   I was wondering if anyone out there could enlighten me on this car I saw the other day. It was a 2-door sports car, looked to be from the late 60s/ early 70s. It was called a Bricklin. The doors were really small. In addition, the front bumper was separate from the rest of the body. This is  all I know. If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.  Thanks, - IL    ---- brought to you by your neighborhood Lerxst ----     \n",
      "__label__4 From: guykuo@carson.u.washington.edu (Guy Kuo) Subject: SI Clock Poll - Final Call Summary: Final call for SI clock reports Keywords: SI,acceleration,clock,upgrade Article-I.D.: shelley.1qvfo9INNc3s Organization: University of Washington Lines: 11 NNTP-Posting-Host: carson.u.washington.edu  A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll. Please send a brief message detailing your experiences with the procedure. Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested.  I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll. Thanks.  Guy Kuo <guykuo@u.washington.edu> \n"
     ]
    }
   ],
   "source": [
    "!head -2 data/newsgroups.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FastText \n",
    "**Install FastText if you haven't!**\n",
    "\n",
    "Use the following commands to install fasttext.\n",
    "```\n",
    "wget https://github.com/facebookresearch/fastText/archive/v0.1.0.zip\n",
    "unzip v0.1.0.zip\n",
    "cd fastText-0.1.0\n",
    "make\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training the fasttext classifier, and check its performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  258366\n",
      "Number of labels: 20\n",
      "Progress: 100.0%  words/sec/thread: 2751034  lr: 0.000000  loss: 2.999579  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "# Train fasttext\n",
    "!./fastText-0.1.0/fastText supervised -input data/newsgroups.train -output data/model_newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t1314\n",
      "P@1\t0.115\n",
      "R@1\t0.115\n",
      "Number of examples: 1314\n"
     ]
    }
   ],
   "source": [
    "# Evaluate it on validation set\n",
    "!./fastText-0.1.0/fastText test data/model_newsgroup.bin data/newsgroups.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that FastText reports the precision and recall, not accuracy!  \n",
    "The **precision** is the number of correct labels among the labels predicted by fastText.  \n",
    "The **recall** is the number of labels that successfully were predicted, among all the real labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improving the model\n",
    "The above model gives poor performance. Let's do some data processing before training.\n",
    "\n",
    "### 3.1 Text Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from lerxst@wam.umd.edu where 's my thing subject what car is this nntp posting host rac3.wam.umd.edu organization university of maryland college park lines 15    i was wondering if anyone out there could enlighten me on this car i saw the other day it was a 2-door sports car looked to be from the late 60s/ early 70s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is   all i know if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail   thanks il     ---- brought to you by your neighborhood lerxst ----\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sent(sent):\n",
    "    temp_sent = ' '.join(sent.split('\\n')) # remove line breaks as fasttext read each sample text as a line\n",
    "    tokens = tokenizer(temp_sent)\n",
    "    pos = [(tok.text, tok.pos_) for tok in tokens]\n",
    "    processed_toks = [tok.text.lower() for tok in tokens if (tok.text not in punctuations)]\n",
    "    \n",
    "    return ' '.join(processed_toks).strip() #[token.text.lower() for token in tokens]\n",
    "    \n",
    "    \n",
    "temp = preprocess_sent(train_data[0])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_newsgroup_file(data, targets, outfile_name):\n",
    "    with open(outfile_name, 'w') as fout:\n",
    "        for i, sent in enumerate(data):\n",
    "            proc_sent = preprocess_sent(sent)\n",
    "            line = \"__label__\" + str(targets[i]) + \" \" + proc_sent + \"\\n\"\n",
    "            fout.write(line)\n",
    "\n",
    "# this will take a long time           \n",
    "create_newsgroup_file(train_data, train_targets, 'data/newsgroups.proc.train') \n",
    "create_newsgroup_file(val_data, val_targets, 'data/newsgroups.proc.val') \n",
    "create_newsgroup_file(test_data, test_targets, 'data/newsgroups.proc.test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  134132\n",
      "Number of labels: 20\n",
      "Progress: 100.0%  words/sec/thread: 3037630  lr: 0.000000  loss: 2.974690  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText supervised -input data/newsgroups.proc.train -output data/model_newsgroup_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t1314\n",
      "P@1\t0.121\n",
      "R@1\t0.121\n",
      "Number of examples: 1314\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText test data/model_newsgroup_proc.bin data/newsgroups.proc.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train More Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see tiny improvement but still a bad model. Let's adjust the hyperparameters of the model.\n",
    "Fasttext library uses 5 training epochs by default, which is not enough for learning our data. \n",
    "Let's try adjusting the number of epoch to 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is important to note that the two models above aren't strictly comparable.**\n",
    "\n",
    "Each model is randomly initialized at the beginning of the training. So, every time you re-train the model, you will notice that the precision and recall are different.\n",
    "In practice, it's a good idea to train the model with different initializations at least 5 times, and report the min, max, mean, and median stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  134132\n",
      "Number of labels: 20\n",
      "Progress: 100.0%  words/sec/thread: 3080700  lr: 0.000000  loss: 1.170081  eta: 0h0m \n",
      "N\t1314\n",
      "P@1\t0.791\n",
      "R@1\t0.791\n",
      "Number of examples: 1314\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText supervised -input data/newsgroups.proc.train -output data/model_newsgroup_ep30 -epoch 30\n",
    "!./fastText-0.1.0/fastText test data/model_newsgroup_ep30.bin data/newsgroups.proc.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! A huge improvement. \n",
    "Learning rate dictates how fast a model learns. By default, it's 0.05. Model will converge faster with bigger learning rate, though bigger learning rate doesn't always mean better.\n",
    "Let's adjust it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  134132\n",
      "Number of labels: 20\n",
      "Progress: 100.0%  words/sec/thread: 3033714  lr: 0.000000  loss: 0.223415  eta: 0h0m \n",
      "N\t1314\n",
      "P@1\t0.87\n",
      "R@1\t0.87\n",
      "Number of examples: 1314\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText supervised -input data/newsgroups.proc.train -output data/model_newsgroup_biglr -epoch 30 -lr 0.5\n",
    "!./fastText-0.1.0/fastText test data/model_newsgroup_biglr.bin data/newsgroups.proc.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, the results improves! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Using Bag-of-Ngrams\n",
    "\n",
    "Now, instead of using **bags of words**, let's try using **bags of N-grams**. We'll use **Bigrams (N=2)** here.  \n",
    "N-grams provide a sense of word order. \n",
    "\n",
    "Sentence: `\"I love eating pizza\"`  \n",
    "Bigrams for the above sentence: `\"I love\"`, `\"love eating\"`, `\"eating pizza\"`.  \n",
    "By looking at the N-grams, it is possible to reconstruct a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  134132\n",
      "Number of labels: 20\n",
      "Progress: 100.0%  words/sec/thread: 1370155  lr: 0.000000  loss: 0.420135  eta: 0h0m \n",
      "N\t1314\n",
      "P@1\t0.868\n",
      "R@1\t0.868\n",
      "Number of examples: 1314\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText supervised -input data/newsgroups.proc.train -output data/model_newsgroup_ngram \\\n",
    "-epoch 30 -lr 0.5 -wordNgrams 2\n",
    "!./fastText-0.1.0/fastText test data/model_newsgroup_ngram.bin data/newsgroups.proc.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But using n-grams doesn't necessarily improve the prediction performance. One more experiment, try 4-gram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  134132\n",
      "Number of labels: 20\n",
      "Progress: 100.0%  words/sec/thread: 592167  lr: 0.000000  loss: 0.710420  eta: 0h0m \n",
      "N\t1314\n",
      "P@1\t0.842\n",
      "R@1\t0.842\n",
      "Number of examples: 1314\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText supervised -input data/newsgroups.proc.train -output data/model_newsgroup_4gram \\\n",
    "-epoch 30 -lr 0.5 -wordNgrams 4\n",
    "!./fastText-0.1.0/fastText test data/model_newsgroup_4gram.bin data/newsgroups.proc.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may check out other hyperparameters you can adjust on the Fasttext repo: https://github.com/facebookresearch/fastText/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have chosen the best model based on validation performance, we can test how it perform on actual test set.  \n",
    "Be aware, ***never*** tune your model on test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7532\n",
      "P@1\t0.766\n",
      "R@1\t0.766\n",
      "Number of examples: 7532\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.1.0/fastText test data/model_newsgroup_biglr.bin data/newsgroups.proc.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
